{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e1ae91a",
   "metadata": {},
   "source": [
    "# 8. Cross-validation Stacking\n",
    "\n",
    "### 8.1 Cross validation\n",
    "\n",
    "1. Hold-out validation : 학습데이터의 일부를 검증셋으로 분류 후, 나머지만 학습에 사용하고, 검증셋은 모델 성능 검증에 사용\n",
    "\n",
    "2. N-Fold CV : 학습 데이터를 N개의 폴드를 나눈 후..\n",
    "\n",
    "3. Stratified N-Fold CV : 폴드 나눌 때, 종속변수의 분포가 동일하게 폴드를 나누는 방식. 분류학습에서 종속변수의 범주의 분포가 균일하지 않을 때 사용. \n",
    "\n",
    "4. Leave-One-Out(LOO) CV : 샘플의 개수를 N으로 사용한 N-Fold CV. 샘플의 개수가 적을 때 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fac183",
   "metadata": {},
   "source": [
    "### 8.2 Stacking\n",
    "\n",
    "여러 가지 모델(알고리즘 + 피쳐)을 조합해서 하나의 예측값을 얻는 앙상블 방식. 과적합을 피하는 방식.\n",
    "\n",
    "Tip : 일반적으로 데이터 과학 대회에서는 Stacking을 stage 1 또는 stage 2까지만 사용합니다. \n",
    "\n",
    "모델 성능 향상을 이루고자 할 때, 일반적으로 stacking은 가장 마지막에 고려하는 방법입니다. 가장 먼저 고려해야 할 것은 새로운 피쳐 (독립변수)를 구축하는 것이며, 그 다음으로 개별 모델의 하이퍼파라미터 튜닝을 고려합니다. 마지막 단계에서 stacking을 통해 모델의 성능을 끌어올리는 것이 일반적으로 사용하는 방법입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1bb339",
   "metadata": {},
   "source": [
    "참고 : \n",
    "\n",
    "K-Fold는 알고리즘과 피쳐의 조합에 의한, 모델 평가용이지, 최종 모델의 파라미터를 직접 설정하는 것은 아닙니다. 따라서, K-Fold를 통해 모델의 대략적인 성능을 파악한 후, 전체 데이터로 다시 한 번 학습하여 최종 모델을 만듭니다.\n",
    "\n",
    "앙상블 또는 스태킹은 예외임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115b3642",
   "metadata": {},
   "source": [
    "new commit markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aa4831",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
