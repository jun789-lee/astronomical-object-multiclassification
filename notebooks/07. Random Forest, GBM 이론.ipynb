{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60486fd5",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "- Random하게 Forest를 만든다라는 것. 무엇이 Random한가? Tree에 사용되는 feature들과 sample을 랜덤 추출한다는 것으로, Tree의 약점이었던 High-variance를 낮춤. \n",
    "\n",
    "참고 : 피쳐와 샘플링을 랜덤하기 해서 학습 후, 조합을 실시하는 것을 배깅 Bagging이라고 함.\n",
    "\n",
    "포레스트의 예측값을 판단하는 것에는 크게 2가지의 종류가 있음. 평균을 내어, 도출하는 soft-voting과 가장 많이 나온 범주를 최종 예측값으로 결정하는 hard-voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc059e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100,\n",
    "                             min_samples_leaf=10,\n",
    "                             max_features='sqrt',\n",
    "                             max_samples = .5,\n",
    "                             random_state=seed,\n",
    "                             n_jobs = -1)\n",
    "\n",
    "clf.fit(X_trn,y_trn)\n",
    "p_val = clf.predict(X_val)\n",
    "p_tst = clf.predic(tst)\n",
    "\n",
    "# 이런 식으로 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197398c0",
   "metadata": {},
   "source": [
    "시각화를 통해, 모든 결정 트리를 시각화하기는 어렵습니다만, 피쳐 중요도를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e5e1f5",
   "metadata": {},
   "source": [
    "## Gradient Boosting Machine(GBM)\n",
    "\n",
    "- 정형 데이터에서는 GBM 알고리즘이 우세를 보이며, 비정형 데이터에서는 딥러닝 알고리즘이 우세를 보입니다.\n",
    "\n",
    "- 랜덤포레스트를를 한 단계 업그레이드 한 버전입니다. 결정트를 순차적으로 학습을 합니다. 첫 번째 결정트리를 학습시키고, 해당 트리의 오차를 줄이는 방향으로 두 번째 결정트리를 학습시킵니다. 기존에 샘플과, 피쳐의 랜덤성에 의존하여, 트리를 만들어낸 것과는 달리, 첫번째 트리와 두 번째 트리가 어느 정도 관계가 있습니다. (독립성X, 의존함) 이러한 Boosting 방법은 개별 결정 트리의 bias를 효과적으로 감소시켜 성능을 향상시킵니다.\n",
    "\n",
    "## XGBoost vs LightGBM \n",
    "GBM을 구현할 때는 XGBoost 또는 LightGBM 라이브러리를 주로 사용합니다.\n",
    "\n",
    "다음 장에서 같이 LightGBM에 대해 실습해보겠습니다.\n",
    "\n",
    "참고 : LightGBM fit 함수에는 종속변수와 독립변수 뿐만 아니라, 검증 데이터의 종속 변수와 독립변수 또한 입력할 수 있는 eval_set 인자가 존재합니다. eval_metric을 명시하면, 학습 도중에 검증 데이터셋에 대한 평가지표를 같이 보여줍니다.\n",
    "\n",
    "또한, early_stopping_rounds 인자는 특정 조건이 만족하면, 학습을 조기 중단 시켜주는 역할을 합니다. -> 매우 유용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9edf54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
